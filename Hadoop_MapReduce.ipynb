{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMkUjlw_ByKT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjJkXaNo_ZxL"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Mapper Function\n",
        "def mapper(chunk):\n",
        "    \"\"\"\n",
        "    Mapper function to generate word count pairs.\n",
        "    Args:\n",
        "        chunk (str): A chunk of text.\n",
        "    Returns:\n",
        "        list of tuples: List of (word,1) pairs.\n",
        "    \"\"\"\n",
        "    words = chunk.split()\n",
        "    return[(word.lower(), 1) for word in words] # convert to lowercase for case insensitivity\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCv9CBDx_mXh"
      },
      "source": [
        "# Reducer Function\n",
        "def reducer(pairs):\n",
        "    \"\"\"\n",
        "    Reducer function to aggregate word counts.\n",
        "    Args:\n",
        "        pairs (list of tuples): List of (word,count) pairs.\n",
        "    Returns:\n",
        "        dict: Dictionary with words as keys and their counts as values.\n",
        "    \"\"\"\n",
        "    word_counts = defaultdict(int)\n",
        "    for word, count in pairs:\n",
        "        word_counts[word] += count\n",
        "    return dict (word_counts)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MapReduce Simulation Function\n",
        "def mapreduce_simulation(text):\n",
        "    \"\"\"\n",
        "    Simulates a MapReduce workflow for word count.\n",
        "    Args:\n",
        "        text (str): Input text data.\n",
        "    Returns:\n",
        "        dict: Word count results.\n",
        "    \"\"\"\n",
        "    # Split text into chunks (simulate splitting into distributed nodes)\n",
        "    chunks = text.split('\\n')\n",
        "\n",
        "    # Step 1: Map phase\n",
        "    Intermediate_pairs = []\n",
        "    for chunk in chunks:\n",
        "        Intermediate_pairs.extend(mapper(chunk))\n",
        "\n",
        "    # Step 2: Shuffle and Sort (Simulated)\n",
        "    # Group intermediate pairs by key (word)\n",
        "\n",
        "    grouped_pairs = defaultdict(list)\n",
        "    for word, count in Intermediate_pairs:\n",
        "        grouped_pairs[word].append(count)\n",
        "\n",
        "    # Flatten grouped pairs for reduction\n",
        "    flattened_pairs = [(word, sum(counts)) for word, counts in grouped_pairs.items()]\n",
        "\n",
        "    # Step 3: Reduce phase\n",
        "    final_output = reducer(flattened_pairs)\n",
        "    return final_output"
      ],
      "metadata": {
        "id": "4blPhPZEocl8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ORywPh2AEBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7d1a89-cac4-4986-f34b-3564800d21da"
      },
      "source": [
        "# Main Function\n",
        "if __name__ == \"__main__\":\n",
        "    # Input Data\n",
        "    input_data = \"\"\"Hadoop is an open source framework.\n",
        "    Hadoop supports MapReduce programming.\n",
        "    Python is also used for MapReduce simulation.\"\"\"\n",
        "\n",
        "    # Run MapReduce Simulation\n",
        "    word_counts = mapreduce_simulation(input_data)\n",
        "\n",
        "    # Print the Results\n",
        "    print(\"Word Counts:\")\n",
        "    for word, count in word_counts.items():\n",
        "        print(f\"{word}: {count}\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Counts:\n",
            "hadoop: 2\n",
            "is: 2\n",
            "an: 1\n",
            "open: 1\n",
            "source: 1\n",
            "framework.: 1\n",
            "supports: 1\n",
            "mapreduce: 2\n",
            "programming.: 1\n",
            "python: 1\n",
            "also: 1\n",
            "used: 1\n",
            "for: 1\n",
            "simulation.: 1\n"
          ]
        }
      ]
    }
  ]
}