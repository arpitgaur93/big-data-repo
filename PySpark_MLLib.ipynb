{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Set Up PySpark\n",
        "!pip install pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n"
      ],
      "metadata": {
        "id": "MhgG8RK4kPSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee5a113-78f0-4bdb-98d4-61bd1b1f3669"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"PySparkMLlibAssignment\").getOrCreate()"
      ],
      "metadata": {
        "id": "aAjbmTAVkSSp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Load and Explore Data\n",
        "# Load Titanic dataset\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data_path = \"titanic.csv\"\n",
        "!wget $url -O $data_path\n",
        "\n"
      ],
      "metadata": {
        "id": "run53QjSkUoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5292ae0-3a02-4396-c082-52566e9651f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-16 21:56:40--  https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60302 (59K) [text/plain]\n",
            "Saving to: ‘titanic.csv’\n",
            "\n",
            "\rtitanic.csv           0%[                    ]       0  --.-KB/s               \rtitanic.csv         100%[===================>]  58.89K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-01-16 21:56:40 (6.84 MB/s) - ‘titanic.csv’ saved [60302/60302]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
        "\n",
        "# Show schema and basic information\n",
        "df.printSchema()\n",
        "df.show(5)\n",
        "print(f\"Total rows: {df.count()}\")"
      ],
      "metadata": {
        "id": "vOXC7BIekWWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199fce89-57f7-4c11-8b60-2603dcf3ad39"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Total rows: 891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: Data Preprocessing\n",
        "selected_columns = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Survived\"]\n",
        "df = df.select(selected_columns)\n",
        "\n",
        "# Handle missing values\n",
        "median_age = df.approxQuantile(\"Age\", [0.5], 0)[0]\n",
        "df = df.fillna({\"Age\": median_age, \"Fare\": df.approxQuantile(\"Fare\", [0.5],0)[0]})\n",
        "df = df.dropna(subset=[\"Survived\"])\n",
        "\n",
        "# Convert categorical column \"Sex\" to numeric\n",
        "indexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n",
        "df = indexer.fit(df).transform(df)\n",
        "\n",
        "# Assemble features into a single vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"Pclass\", \"SexIndex\", \"Age\", \"Fare\"], outputCol=\"features\")\n",
        "df = assembler.transform(df)"
      ],
      "metadata": {
        "id": "zH6Ybc4BkZKA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only features and target column\n",
        "df = df.select(\"features\", \"Survived\")\n",
        "\n",
        "# Task 4: Train-Test Split\n",
        "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Task 5: Train a Logistic Regression Model and Display model coefficients and intercept\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Survived\")\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "# Display model coefficients and intercept\n",
        "print(f\"Coefficients: {lr_model.coefficients}\")\n",
        "print(f\" Intercept: {lr_model.intercept}\")\n"
      ],
      "metadata": {
        "id": "GcoBN9yJkb3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e41c390-29bb-4591-a2b8-2276dd63859e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [-1.0485232298342673,2.602193522818644,-0.02450847389465579,0.000866680973489534]\n",
            " Intercept: 1.6039307167876704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GLfjDo8LWpTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e9eea5-b2c3-4fef-b024-4fbad4faf93a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.8476003597416402\n",
            "Accuracy: 0.0033813912009512483\n"
          ]
        }
      ],
      "source": [
        "# Task 6: Model Evaluation\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "#Evaluate Model\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"Survived\", metricName=\"areaUnderROC\")\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f\"AUC: {auc}\")\n",
        "\n",
        "#Calculate accuracy\n",
        "accuracy = predictions.filter(predictions[\"Survived\"] == predictions[\"prediction\"]).count() / predictions.count()/float(test_data.count())\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 7: Hyperparameter Tuning\n",
        "param_grid = ParamGridBuilder() \\\n",
        "     .addGrid(lr.regParam, [0.01, 0.1, 1.0])\\\n",
        "     .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
        "     .build()\n",
        "\n",
        "crossval = CrossValidator(estimator=lr, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
        "cv_model = crossval.fit(train_data)\n",
        "best_model = cv_model.bestModel\n",
        "\n",
        "# Best Hyperparameter\n",
        "print(f\"Best RegParam: {best_model._java_obj.getRegParam()}\")\n",
        "print(f\"Best ElasticNetParam: {best_model._java_obj.getElasticNetParam()}\")\n",
        "\n",
        "# Evaluate best model on test data\n",
        "best_predictions = best_model.transform(test_data)\n",
        "best_auc = evaluator.evaluate(best_predictions)\n",
        "print(f\"Best Model AUC: {best_auc}\")\n"
      ],
      "metadata": {
        "id": "Dt2bK8tEkd-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5721f74-304a-408d-8d87-381986d43d54"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RegParam: 0.1\n",
            "Best ElasticNetParam: 0.0\n",
            "Best Model AUC: 0.8398332106941377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZYuHDB8XYlA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}